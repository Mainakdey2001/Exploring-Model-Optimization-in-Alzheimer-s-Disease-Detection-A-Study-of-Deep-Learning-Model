# -*- coding: utf-8 -*-
"""Alzheimer Detection 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fg61R6h-VNOCkoVcy7hpVYaZ9c7wBajT
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
import os
import pathlib
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing import image_dataset_from_directory
import itertools

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 
for dirpath, dirnames, filenames in os.walk("/content/drive/MyDrive/Alzeimer Dtection data/train data 3"):
    print(f"{len(dirnames)} dirs and {len(filenames)} images in '{dirpath}'")

data_dir = "/content/drive/MyDrive/Alzeimer Dtection data/train data 3"
path_dir = pathlib.Path("/content/drive/MyDrive/Alzeimer Dtection data/train data 3") 
class_names = np.array(sorted([item.name for item in path_dir.glob('*')]))
print(class_names)

def view_random_image(target_dir, target_class):
    target_folder = target_dir + target_class
    random_image = random.sample(os.listdir(target_folder), 1)
    img = mpimg.imread(target_folder + "/" + random_image[0])
    plt.imshow(img)
    plt.title(target_class)
    plt.axis("off");

    print(f"Image shape: {img.shape}")
    return img

def view_image(directory):
  img = mpimg.imread(directory)
  plt.imshow(img)
  plt.title(directory)
  plt.axis('off')
  print(f'Image shape:{img.shape}')
  return img
print('One of the data in Mild_Demented Alzheimer Folder')
view_image("/content/drive/MyDrive/Alzeimer Dtection data/train  data 2/Mild_Demented/mild_101.jpg")

def view_image(directory):
  img = mpimg.imread(directory)
  plt.imshow(img)
  plt.title(directory)
  plt.axis('off')
  print(f'Image shape:{img.shape}')
  return img
print('One of the data in Moderate_Demented Alzheimer Folder')
view_image("/content/drive/MyDrive/Alzeimer Dtection data/train  data 2/Moderate_Demented/moderate_11.jpg")

def view_image(directory):
  img = mpimg.imread(directory)
  plt.imshow(img)
  plt.title(directory)
  plt.axis('off')
  print(f'Image shape:{img.shape}')
  return img
print('One of the data in Non_Demented Alzheimer Folder')
view_image("/content/drive/MyDrive/Alzeimer Dtection data/train  data 2/Non_Demented/non_101.jpg")

def view_image(directory):
  img = mpimg.imread(directory)
  plt.imshow(img)
  plt.title(directory)
  plt.axis('off')
  print(f'Image shape:{img.shape}')
  return img
print('One of the data in Very_Mild_Demented Alzheimer Folder')
view_image("/content/drive/MyDrive/Alzeimer Dtection data/train  data 2/Very_Mild_Demented/verymild_102.jpg")

# For replicable results
SEED = 0
# Size of the images is (128,128)
IMAGE_SIZE = (128, 128)
# Default batch size
BATCH_SIZE = 32
# Images are grayscale
COLOR_MODE = "grayscale"
# 20% test split
VAL_SPLIT = 0.2

tf.random.set_seed(SEED)
np.random.seed(SEED)
train_data = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    label_mode='categorical',
    validation_split=VAL_SPLIT,
    subset="training",
    seed=SEED,
    color_mode=COLOR_MODE,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
)
valid_data = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=VAL_SPLIT,
    subset="validation",
    label_mode='categorical',
    seed=SEED,
    color_mode=COLOR_MODE,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
)

base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model.trainable = True
inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE+(1,)), name="input_layer")
# Efficient net model has the normalizing layer builtin
x = base_model(inputs)
x = tf.keras.layers.GlobalAveragePooling2D(name="global_average_pooling_layer")(x)
outputs = tf.keras.layers.Dense(len(class_names), activation="softmax", name="output_layer")(x)

model = tf.keras.Model(inputs, outputs)

# Default Learning rate
LR = 0.001

model.compile(loss="categorical_crossentropy", 
                optimizer=tf.keras.optimizers.Adam(learning_rate=LR), 
                metrics=["accuracy"])

model.summary()

# Epochs
EPOCHS = 90
history = model.fit(train_data,
                      validation_data=valid_data,
                      epochs=EPOCHS,
                      verbose=False
                      )

pd.DataFrame(history.history).plot(figsize=(10, 7));

model.evaluate(valid_data)
